{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1dd07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gsm8 import GSM8KLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model directly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  25%|██▌       | 1/4 [00:10<00:31, 10.40s/it]"
     ]
    }
   ],
   "source": [
    "# Direct loading - much faster\n",
    "print(\"Loading model directly...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-7B\", \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=\"half\",\n",
    "    device_map=\"cuda\",\n",
    "    use_cache=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading math problems...\")\n",
    "dataset = GSM8KLoader()\n",
    "\n",
    "# Get 10 math problems\n",
    "math_problems = []\n",
    "for i in range(10):\n",
    "    item = dataset[i]\n",
    "    math_problems.append(item['question'])\n",
    "    print(f\"{i+1}. {item['question']}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(math_problems)} math problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some non-math control sentences\n",
    "non_math_text = [\n",
    "    \"The cat sat on the comfortable mat in the living room.\",\n",
    "    \"Yesterday I went to the store to buy groceries for dinner.\",\n",
    "    \"She loves reading books about history and ancient civilizations.\",\n",
    "    \"The weather today is sunny with a gentle breeze blowing.\",\n",
    "    \"Music has the power to inspire and heal people's hearts.\",\n",
    "    \"Traveling to new places opens your mind to different cultures.\",\n",
    "    \"Technology continues to evolve at an unprecedented pace today.\",\n",
    "    \"Cooking delicious meals brings families together around the table.\",\n",
    "    \"Exercise and healthy eating are important for maintaining wellness.\",\n",
    "    \"Art museums showcase creativity and human expression throughout history.\"\n",
    "]\n",
    "\n",
    "print(\"Non-math control sentences:\")\n",
    "for i, text in enumerate(non_math_text):\n",
    "    print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_activations_direct(model, tokenizer, problems, target_layers=range(20, 27)):\n",
    "    \"\"\"Collect max activations across specified layers\"\"\"\n",
    "    activations_data = {layer: [] for layer in target_layers}\n",
    "    \n",
    "    for i, problem in enumerate(problems):\n",
    "        print(f\"Processing {i+1}/{len(problems)}: {problem[:50]}...\")\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(problem, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "        \n",
    "        # Forward pass with hooks\n",
    "        layer_outputs = {}\n",
    "        \n",
    "        def make_hook(layer_idx):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    activation = output[0].detach()\n",
    "                else:\n",
    "                    activation = output.detach()\n",
    "                # Get max absolute activation for this layer\n",
    "                layer_outputs[layer_idx] = torch.max(torch.abs(activation)).item()\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks\n",
    "        hooks = []\n",
    "        for layer_idx in target_layers:\n",
    "            layer = model.model.layers[layer_idx]  # Note: model.model.layers for Qwen\n",
    "            hook = layer.register_forward_hook(make_hook(layer_idx))\n",
    "            hooks.append(hook)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "        \n",
    "        # Store results\n",
    "        for layer_idx in target_layers:\n",
    "            activations_data[layer_idx].append(layer_outputs.get(layer_idx, 0))\n",
    "        \n",
    "        # Clean up hooks\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "    \n",
    "    return activations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing math problems...\")\n",
    "math_activations = collect_activations_direct(model, tokenizer, math_problems)\n",
    "\n",
    "print(\"\\nMath activation statistics:\")\n",
    "for layer in range(20, 27):\n",
    "    values = math_activations[layer]\n",
    "    print(f\"Layer {layer}: Mean={np.mean(values):.3f}, Max={np.max(values):.3f}, Std={np.std(values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing non-math text...\")\n",
    "non_math_activations = collect_activations_direct(model, tokenizer, non_math_text)\n",
    "\n",
    "print(\"\\nNon-math activation statistics:\")\n",
    "for layer in range(20, 27):\n",
    "    values = non_math_activations[layer]\n",
    "    print(f\"Layer {layer}: Mean={np.mean(values):.3f}, Max={np.max(values):.3f}, Std={np.std(values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5af788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_analysis(math_data, non_math_data):\n",
    "    \"\"\"Create clean plots comparing math vs non-math activations\"\"\"\n",
    "    layers = list(math_data.keys())\n",
    "    \n",
    "    # Calculate statistics\n",
    "    math_means = [np.mean(math_data[layer]) for layer in layers]\n",
    "    math_maxs = [np.max(math_data[layer]) for layer in layers]\n",
    "    non_math_means = [np.mean(non_math_data[layer]) for layer in layers]\n",
    "    non_math_maxs = [np.max(non_math_data[layer]) for layer in layers]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: Mean activations\n",
    "    ax1.plot(layers, math_means, 'o-', color='red', linewidth=2, markersize=8, label='Math Problems', alpha=0.8)\n",
    "    ax1.plot(layers, non_math_means, 'o-', color='blue', linewidth=2, markersize=8, label='Non-Math Text', alpha=0.8)\n",
    "    ax1.axvline(x=23, color='orange', linestyle='--', alpha=0.7, linewidth=2, label='Layer 23')\n",
    "    ax1.set_xlabel('Layer Number', fontsize=12)\n",
    "    ax1.set_ylabel('Mean Max Activation', fontsize=12)\n",
    "    ax1.set_title('Mean Maximum Activations Across Layers', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xticks(layers)\n",
    "    \n",
    "    # Plot 2: Max activations\n",
    "    ax2.plot(layers, math_maxs, 's-', color='red', linewidth=2, markersize=8, label='Math Problems', alpha=0.8)\n",
    "    ax2.plot(layers, non_math_maxs, 's-', color='blue', linewidth=2, markersize=8, label='Non-Math Text', alpha=0.8)\n",
    "    ax2.axvline(x=23, color='orange', linestyle='--', alpha=0.7, linewidth=2, label='Layer 23')\n",
    "    ax2.set_xlabel('Layer Number', fontsize=12)\n",
    "    ax2.set_ylabel('Peak Max Activation', fontsize=12)\n",
    "    ax2.set_title('Peak Maximum Activations Across Layers', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xticks(layers)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\n=== LAYER 23 ANALYSIS ===\")\n",
    "    layer_23_idx = layers.index(23)\n",
    "    print(f\"Math problems - Mean: {math_means[layer_23_idx]:.3f}, Max: {math_maxs[layer_23_idx]:.3f}\")\n",
    "    print(f\"Non-math text - Mean: {non_math_means[layer_23_idx]:.3f}, Max: {non_math_maxs[layer_23_idx]:.3f}\")\n",
    "    if non_math_means[layer_23_idx] > 0:\n",
    "        print(f\"Ratio (Math/Non-math) - Mean: {math_means[layer_23_idx]/non_math_means[layer_23_idx]:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating plots...\")\n",
    "plot_activation_analysis(math_activations, non_math_activations)\n",
    "print(\"Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at raw activation values for debugging\n",
    "print(\"Raw activation values for Layer 23:\")\n",
    "print(\"Math problems:\", math_activations[23])\n",
    "print(\"Non-math text:\", non_math_activations[23])\n",
    "\n",
    "# Show the difference\n",
    "math_layer23 = np.array(math_activations[23])\n",
    "nonmath_layer23 = np.array(non_math_activations[23])\n",
    "print(f\"\\nLayer 23 activation comparison:\")\n",
    "print(f\"Math mean: {math_layer23.mean():.3f} ± {math_layer23.std():.3f}\")\n",
    "print(f\"Non-math mean: {nonmath_layer23.mean():.3f} ± {nonmath_layer23.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciurus-env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
