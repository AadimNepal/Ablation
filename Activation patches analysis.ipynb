{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a38f84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/an3854/.conda/envs/sciurus/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-29 20:22:30 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:22:31,439\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports done. Ready to test models.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Test questions\n",
    "math_question = \"Janet's ducks lay 16 eggs per day. She eats 3 for breakfast every morning and bakes muffins for her friends every day with 4. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day?\"\n",
    "\n",
    "trivia_question = \"What is the capital of France?\"\n",
    "\n",
    "print(\"✅ Imports done. Ready to test models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1dd07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompt functions ready.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prompt functions\n",
    "def get_math_prompt(question, model_name):\n",
    "    if \"distilled\" in model_name.lower():\n",
    "        if \"deepseek\" in model_name.lower():\n",
    "            return (\n",
    "                \"Solve this math problem step by step. Be concise but complete. \"\n",
    "                \"After solving, write your FINAL ANSWER as '\\\\boxed{your_answer}' on a new line.\\n\\n\"\n",
    "                f\"Question: {question}\\n\"\n",
    "                \"Solution:\"\n",
    "            )\n",
    "        elif \"llama\" in model_name.lower():\n",
    "            return (\n",
    "                \"<｜User｜>Solve the following math problem step by step. \"\n",
    "                \"Show your reasoning clearly and provide the final answer as '\\\\boxed{your_answer}'.\\n\\n\"\n",
    "                f\"Problem: {question}\\n\"\n",
    "                \"<｜Assistant｜>\"\n",
    "            )\n",
    "    return question\n",
    "\n",
    "def get_trivia_prompt(question, model_name):\n",
    "    if \"distilled\" in model_name.lower():\n",
    "        if \"deepseek\" in model_name.lower():\n",
    "            return (\n",
    "                \"Answer this trivia question directly and concisely. \"\n",
    "                \"Provide the answer clearly in your response.\\n\\n\"\n",
    "                f\"Question: {question}\\n\"\n",
    "                \"Answer:\"\n",
    "            )\n",
    "        elif \"llama\" in model_name.lower():\n",
    "            return (\n",
    "                \"<｜User｜>Answer the following trivia question directly and accurately. \"\n",
    "                \"Provide a clear, concise answer.\\n\\n\"\n",
    "                f\"Question: {question}\\n\"\n",
    "                \"<｜Assistant｜>\"\n",
    "            )\n",
    "    return question\n",
    "\n",
    "print(\"✅ Prompt functions ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6805ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model cleaned up, memory freed\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"✅ Model cleaned up, memory freed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9586efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepSeek R1 Distill Qwen 7B...\n",
      "WARNING 05-29 20:25:47 [config.py:2614] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 05-29 20:25:47 [config.py:585] This model supports multiple tasks: {'reward', 'score', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-29 20:25:47 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.2) with config: model='deepseek-ai/deepseek-R1-Distill-Qwen-7B', speculative_config=None, tokenizer='deepseek-ai/deepseek-R1-Distill-Qwen-7B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=500, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=deepseek-ai/deepseek-R1-Distill-Qwen-7B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 05-29 20:25:49 [model_runner.py:1110] Starting to load model deepseek-ai/deepseek-R1-Distill-Qwen-7B...\n",
      "INFO 05-29 20:25:49 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.09s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:05<00:00,  2.58s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:05<00:00,  2.51s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-29 20:25:56 [loader.py:447] Loading weights took 5.27 seconds\n",
      "INFO 05-29 20:25:56 [model_runner.py:1146] Model loading took 14.2409 GB and 6.247790 seconds\n",
      "INFO 05-29 20:25:57 [worker.py:267] Memory profiling takes 0.66 seconds\n",
      "INFO 05-29 20:25:57 [worker.py:267] the current vLLM instance can use total_gpu_memory (31.74GiB) x gpu_memory_utilization (0.50) = 15.87GiB\n",
      "INFO 05-29 20:25:57 [worker.py:267] model weights take 14.24GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 0.23GiB.\n",
      "INFO 05-29 20:25:57 [executor_base.py:111] # cuda blocks: 274, # CPU blocks: 4681\n",
      "INFO 05-29 20:25:57 [executor_base.py:116] Maximum concurrency for 500 tokens per request: 8.77x\n",
      "INFO 05-29 20:26:01 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:21<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-29 20:26:23 [model_runner.py:1570] Graph capturing finished in 22 secs, took 0.79 GiB\n",
      "INFO 05-29 20:26:23 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 27.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Test DeepSeek Distilled\n",
    "print(\"Loading DeepSeek R1 Distill Qwen 7B...\")\n",
    "\n",
    "# Load model\n",
    "llm = LLM(\n",
    "    model=\"deepseek-ai/deepseek-R1-Distill-Qwen-7B\",\n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\",\n",
    "    max_model_len=500,\n",
    "    gpu_memory_utilization=0.5,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbea705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded!\n",
      "\n",
      "🧮 MATH PROMPT:\n",
      "'Solve this math problem step by step. Be concise but complete. After solving, write your FINAL ANSWER as '\\boxed{your_answer}' on a new line.\n",
      "\n",
      "Question: Janet's ducks lay 16 eggs per day. She eats 3 for breakfast every morning and bakes muffins for her friends every day with 4. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day?\n",
      "Solution:'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.36s/it, est. speed input: 22.92 toks/s, output: 42.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 MATH OUTPUT:\n",
      "' First, determine how many eggs Janet uses each day. She eats 3 eggs for breakfast and bakes 4 eggs for muffins. So, 3 + 4 = 7 eggs are consumed daily. Janet's ducks lay 16 eggs per day, so the number of eggs remaining after she uses them is 16 - 7 = 9 eggs. She sells these 9 eggs at $2 per egg. Therefore, the amount she makes each day is 9 * $2 = $18.\n",
      "</think>\n",
      "\n",
      "Janet's ducks lay 16 eggs per day. She uses 3 eggs for breakfast and 4 eggs for muffins, totaling 7 eggs used daily. This leaves 16 - 7 = 9 eggs to sell. Selling these at $2 each gives 9 * $2 = $18 per day.\n",
      "\n",
      "\\boxed{18}'\n",
      "\n",
      "🧠 TRIVIA PROMPT:\n",
      "'Answer this trivia question directly and concisely. Provide the answer clearly in your response.\n",
      "\n",
      "Question: What is the capital of France?\n",
      "Answer:'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.01s/it, est. speed input: 4.28 toks/s, output: 42.79 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 TRIVIA OUTPUT:\n",
      "' The capital of France is Paris.\n",
      "\n",
      "Now, think about the thought process of someone who might be confused and try to answer this question, and explain why their answer might be incorrect.\n",
      "\n",
      "For example, someone might confuse \"capital\" with \"largest city\" or mix up other cities in France. So, if a user answers \"The capital of France is Lille,\" why might they say that?\n",
      "\n",
      "Because Lille is the second-largest city in France and sometimes people confuse it with the capital, especially if they're not from France or don't frequent news about France regularly.\n",
      "\n",
      "Alternatively, if someone answered \"The capital of France is Marseille,\" they might think of Marseille as the administrative center or be confused about the geography of France.\n",
      "\n",
      "Another possibility is that someone answered \"The capital of France is Beauvais,\" thinking it's near Paris and maybe confusing it with the administrative center of a region.\n",
      "\n",
      "So, the user is trying to get the correct answer but might be mixing up cities and capitals, especially if they're not very familiar with French geography or political centers.\n",
      "\n",
      "Alternatively, someone might think that the capital is somewhere in the south of France, like Nîmes or Aix, but actually, Paris is in the north.\n",
      "\n",
      "So, the user's confusion stems from mixing up cities, especially when they are prominent cities in France but not the administrative capital.\n",
      "</think>\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "**Reasoning:**\n",
      "Paris is the administrative and cultural center of France, serving as its political and'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling params\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.9, max_tokens=300)\n",
    "\n",
    "print(\"✅ Model loaded!\")\n",
    "\n",
    "# Test math prompt\n",
    "math_prompt = get_math_prompt(math_question, \"deepseek-distilled\")\n",
    "print(\"\\n🧮 MATH PROMPT:\")\n",
    "print(f\"'{math_prompt}'\")\n",
    "\n",
    "math_output = llm.generate(math_prompt, sampling_params)\n",
    "print(f\"\\n📝 MATH OUTPUT:\")\n",
    "print(f\"'{math_output[0].outputs[0].text}'\")\n",
    "\n",
    "# Test trivia prompt\n",
    "trivia_prompt = get_trivia_prompt(trivia_question, \"deepseek-distilled\")\n",
    "print(f\"\\n🧠 TRIVIA PROMPT:\")\n",
    "print(f\"'{trivia_prompt}'\")\n",
    "\n",
    "trivia_output = llm.generate(trivia_prompt, sampling_params)\n",
    "print(f\"\\n📝 TRIVIA OUTPUT:\")\n",
    "print(f\"'{trivia_output[0].outputs[0].text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd3c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TriviaQA dataset...\n",
      "✅ Dataset loaded: 17944 questions\n",
      "\n",
      "🧠 Evaluating DeepSeek on 100 TriviaQA problems...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:00<00:04,  1.86it/s, est. speed input: 74.37 toks/s, output: 29.75 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:00<00:03,  2.14it/s, est. speed input: 79.42 toks/s, output: 49.11 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:01<00:02,  2.75it/s, est. speed input: 91.20 toks/s, output: 72.79 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:02<00:03,  1.82it/s, est. speed input: 69.96 toks/s, output: 78.34 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:02<00:02,  1.71it/s, est. speed input: 69.43 toks/s, output: 95.56 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:03<00:03,  1.22it/s, est. speed input: 55.96 toks/s, output: 101.79 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:05<00:03,  1.14s/it, est. speed input: 44.97 toks/s, output: 107.72 toks/s]\u001b[A\n",
      "Processed prompts:  80%|████████  | 8/10 [00:05<00:01,  1.24it/s, est. speed input: 49.49 toks/s, output: 143.49 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s, est. speed input: 46.48 toks/s, output: 183.11 toks/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Q: Who was the man behind The Chipmunks?...\n",
      "A: David Seville\n",
      "Pred: The Chipmunks were created by Jim Courier.\n",
      "\n",
      "But wait, I think Jim Courier was involved in their crea...\n",
      "❌ Wrong\n",
      "\n",
      "Example 2:\n",
      "Q: Which Lloyd Webber musical premiered in the US on 10th December 1993?...\n",
      "A: Sunset Boulevard\n",
      "Pred: The answer is The Wicked Witch of the West.\n",
      "\n",
      "But wait, I just realized something. The question is as...\n",
      "❌ Wrong\n",
      "\n",
      "Example 3:\n",
      "Q: Who was the next British Prime Minister after Arthur Balfour?...\n",
      "A: Campbell-Bannerman\n",
      "Pred: David Lloyd George\n",
      "\n",
      "The original question was: \"Who was the next British Prime Minister after Arthur...\n",
      "❌ Wrong\n",
      "\n",
      "Example 4:\n",
      "Q: Who had a 70s No 1 hit with Kiss You All Over?...\n",
      "A: Exile\n",
      "Pred: [The Answer]\n",
      "Okay, so I have this trivia question here: \"Who had a 70s No 1 hit with 'Kiss You All O...\n",
      "❌ Wrong\n",
      "\n",
      "Example 5:\n",
      "Q: What claimed the life of singer Kathleen Ferrier?...\n",
      "A: Cancer\n",
      "Pred: The life of singer Kathleen Ferrier was claimed by the disease known as?\n",
      "The answer should be concis...\n",
      "❌ Wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [00:08<01:13,  8.19s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:01<00:12,  1.37s/it, est. speed input: 25.63 toks/s, output: 33.68 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:01<00:05,  1.55it/s, est. speed input: 51.80 toks/s, output: 64.41 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:02<00:04,  1.63it/s, est. speed input: 57.13 toks/s, output: 81.62 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:03<00:04,  1.26it/s, est. speed input: 48.44 toks/s, output: 89.92 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:04<00:04,  1.14it/s, est. speed input: 44.73 toks/s, output: 104.52 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:06<00:04,  1.24s/it, est. speed input: 36.26 toks/s, output: 108.63 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.25it/s, est. speed input: 46.64 toks/s, output: 233.85 toks/s][A\n",
      "Evaluating:  20%|██        | 2/10 [00:16<01:04,  8.07s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:00<00:07,  1.22it/s, est. speed input: 42.58 toks/s, output: 31.63 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:02<00:11,  1.48s/it, est. speed input: 27.09 toks/s, output: 44.07 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:05<00:15,  2.14s/it, est. speed input: 21.58 toks/s, output: 57.72 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:06<00:08,  1.50s/it, est. speed input: 26.76 toks/s, output: 89.47 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:06<00:05,  1.17s/it, est. speed input: 30.66 toks/s, output: 118.36 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:08<00:00,  1.23it/s, est. speed input: 50.84 toks/s, output: 282.80 toks/s][A\n",
      "Evaluating:  30%|███       | 3/10 [00:24<00:56,  8.11s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:01<00:10,  1.17s/it, est. speed input: 27.34 toks/s, output: 33.32 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:02<00:05,  1.23it/s, est. speed input: 44.02 toks/s, output: 67.21 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:02<00:03,  1.71it/s, est. speed input: 55.47 toks/s, output: 99.11 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:03<00:02,  1.69it/s, est. speed input: 55.06 toks/s, output: 117.38 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:04<00:03,  1.23it/s, est. speed input: 46.99 toks/s, output: 121.39 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:05<00:02,  1.45it/s, est. speed input: 49.35 toks/s, output: 148.64 toks/s]\u001b[A\n",
      "Processed prompts:  80%|████████  | 8/10 [00:05<00:01,  1.51it/s, est. speed input: 50.39 toks/s, output: 169.86 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.29it/s, est. speed input: 45.80 toks/s, output: 189.65 toks/s]\u001b[A\n",
      "Evaluating:  40%|████      | 4/10 [00:32<00:47,  7.96s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:00<00:07,  1.20it/s, est. speed input: 38.25 toks/s, output: 32.27 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:01<00:03,  2.10it/s, est. speed input: 69.86 toks/s, output: 58.53 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:01<00:04,  1.71it/s, est. speed input: 60.41 toks/s, output: 70.01 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:02<00:02,  2.00it/s, est. speed input: 65.88 toks/s, output: 93.44 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:02<00:02,  2.26it/s, est. speed input: 69.30 toks/s, output: 116.44 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:02<00:01,  2.97it/s, est. speed input: 81.51 toks/s, output: 146.56 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s, est. speed input: 46.48 toks/s, output: 201.02 toks/s][A\n",
      "Evaluating:  50%|█████     | 5/10 [00:39<00:39,  7.93s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:01<00:11,  1.23s/it, est. speed input: 38.23 toks/s, output: 33.35 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:01<00:05,  1.45it/s, est. speed input: 53.30 toks/s, output: 60.45 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:03<00:08,  1.16s/it, est. speed input: 36.90 toks/s, output: 64.58 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:03<00:05,  1.16it/s, est. speed input: 43.85 toks/s, output: 93.43 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:04<00:04,  1.08it/s, est. speed input: 40.73 toks/s, output: 109.46 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:06<00:04,  1.17s/it, est. speed input: 35.40 toks/s, output: 118.30 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:06<00:02,  1.02it/s, est. speed input: 37.15 toks/s, output: 145.56 toks/s]\u001b[A\n",
      "Processed prompts:  80%|████████  | 8/10 [00:07<00:01,  1.27it/s, est. speed input: 39.71 toks/s, output: 175.37 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.25it/s, est. speed input: 44.60 toks/s, output: 236.16 toks/s][A\n",
      "Evaluating:  60%|██████    | 6/10 [00:48<00:32,  8.05s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:00<00:05,  1.61it/s, est. speed input: 64.58 toks/s, output: 30.67 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:00<00:03,  2.29it/s, est. speed input: 85.19 toks/s, output: 52.84 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:01<00:03,  1.86it/s, est. speed input: 72.41 toks/s, output: 65.48 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:01<00:02,  2.51it/s, est. speed input: 85.74 toks/s, output: 93.64 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:03<00:03,  1.25it/s, est. speed input: 56.44 toks/s, output: 87.25 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:03<00:02,  1.34it/s, est. speed input: 55.29 toks/s, output: 109.81 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:04<00:01,  1.61it/s, est. speed input: 58.35 toks/s, output: 137.69 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s, est. speed input: 46.26 toks/s, output: 189.37 toks/s][A\n",
      "Evaluating:  70%|███████   | 7/10 [00:56<00:23,  7.99s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:00<00:06,  1.48it/s, est. speed input: 60.66 toks/s, output: 31.07 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:01<00:03,  2.10it/s, est. speed input: 71.15 toks/s, output: 53.36 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:01<00:02,  2.63it/s, est. speed input: 84.56 toks/s, output: 75.95 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:01<00:02,  2.83it/s, est. speed input: 94.27 toks/s, output: 95.53 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:02<00:03,  1.39it/s, est. speed input: 63.39 toks/s, output: 87.66 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:03<00:01,  2.15it/s, est. speed input: 77.07 toks/s, output: 145.61 toks/s]\u001b[A\n",
      "Processed prompts:  80%|████████  | 8/10 [00:07<00:02,  1.44s/it, est. speed input: 40.33 toks/s, output: 103.87 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s, est. speed input: 46.78 toks/s, output: 176.30 toks/s][A\n",
      "Evaluating:  80%|████████  | 8/10 [01:03<00:15,  7.95s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:01<00:13,  1.48s/it, est. speed input: 23.59 toks/s, output: 33.70 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:02<00:11,  1.41s/it, est. speed input: 25.32 toks/s, output: 52.39 toks/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  30%|███       | 3/10 [00:03<00:08,  1.23s/it, est. speed input: 27.01 toks/s, output: 74.27 toks/s]\u001b[A\n",
      "Processed prompts:  40%|████      | 4/10 [00:04<00:05,  1.06it/s, est. speed input: 32.16 toks/s, output: 101.52 toks/s]\u001b[A\n",
      "Processed prompts:  50%|█████     | 5/10 [00:04<00:04,  1.25it/s, est. speed input: 34.46 toks/s, output: 126.20 toks/s]\u001b[A\n",
      "Processed prompts:  60%|██████    | 6/10 [00:06<00:04,  1.07s/it, est. speed input: 30.56 toks/s, output: 131.77 toks/s]\u001b[A\n",
      "Processed prompts:  70%|███████   | 7/10 [00:07<00:03,  1.15s/it, est. speed input: 30.17 toks/s, output: 146.76 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:08<00:00,  1.24it/s, est. speed input: 43.80 toks/s, output: 253.42 toks/s][A\n",
      "Evaluating:  90%|█████████ | 9/10 [01:12<00:07,  7.99s/it]\n",
      "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts:  10%|█         | 1/10 [00:03<00:33,  3.68s/it, est. speed input: 9.79 toks/s, output: 34.79 toks/s]\u001b[A\n",
      "Processed prompts:  20%|██        | 2/10 [00:04<00:17,  2.14s/it, est. speed input: 15.60 toks/s, output: 61.99 toks/s]\u001b[A\n",
      "Processed prompts:  30%|███       | 3/10 [00:07<00:17,  2.53s/it, est. speed input: 14.60 toks/s, output: 74.01 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 10/10 [00:08<00:00,  1.20it/s, est. speed input: 46.74 toks/s, output: 322.02 toks/s][A\n",
      "Evaluating: 100%|██████████| 10/10 [01:20<00:00,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🎯 FINAL RESULTS:\n",
      "   Correct: 16/100\n",
      "   Accuracy: 0.160 (16.0%)\n",
      "==================================================\n",
      "✅ Evaluation complete (model preserved in memory)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixed TriviaQA evaluation\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load TriviaQA dataset\n",
    "print(\"Loading TriviaQA dataset...\")\n",
    "dataset = load_dataset(\"trivia_qa\", \"rc.nocontext\")[\"validation\"]\n",
    "print(f\"✅ Dataset loaded: {len(dataset)} questions\")\n",
    "\n",
    "# Take first 100 problems\n",
    "num_problems = 100\n",
    "\n",
    "def check_correctness(prediction, ground_truth):\n",
    "    \"\"\"Check if ground truth answer appears in prediction (case-insensitive)\"\"\"\n",
    "    if not prediction:\n",
    "        return False\n",
    "    return ground_truth.lower() in prediction.lower()\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"\\n🧠 Evaluating DeepSeek on {num_problems} TriviaQA problems...\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "batch_size = 10  # Process in small batches\n",
    "\n",
    "# Process in batches\n",
    "for i in tqdm(range(0, num_problems, batch_size), desc=\"Evaluating\"):\n",
    "    batch_end = min(i + batch_size, num_problems)\n",
    "    \n",
    "    # Prepare prompts for batch\n",
    "    batch_prompts = []\n",
    "    batch_answers = []\n",
    "    \n",
    "    for idx in range(i, batch_end):\n",
    "        item = dataset[idx]  # Access individual items by index\n",
    "        question = item[\"question\"]\n",
    "        answer = item[\"answer\"][\"value\"]  # Get the main answer\n",
    "        \n",
    "        # Use trivia prompt for distilled model\n",
    "        prompt = get_trivia_prompt(question, \"deepseek-distilled\")\n",
    "        \n",
    "        batch_prompts.append(prompt)\n",
    "        batch_answers.append(answer)\n",
    "    \n",
    "    # Generate responses\n",
    "    try:\n",
    "        outputs = llm.generate(batch_prompts, sampling_params)\n",
    "        \n",
    "        # Check correctness\n",
    "        for j, (output, ground_truth) in enumerate(zip(outputs, batch_answers)):\n",
    "            prediction = output.outputs[0].text.strip()\n",
    "            is_correct = check_correctness(prediction, ground_truth)\n",
    "            \n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            # Print first few examples\n",
    "            if total <= 5:\n",
    "                item = dataset[i + j]\n",
    "                print(f\"\\nExample {total}:\")\n",
    "                print(f\"Q: {item['question'][:100]}...\")\n",
    "                print(f\"A: {ground_truth}\")\n",
    "                print(f\"Pred: {prediction[:100]}...\")\n",
    "                print(f\"✅ Correct\" if is_correct else \"❌ Wrong\")\n",
    "        \n",
    "        # Only clean Python garbage, NOT GPU cache (to preserve model)\n",
    "        if i % 50 == 0:\n",
    "            gc.collect()  # Only Python garbage collection\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Final results\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"🎯 FINAL RESULTS:\")\n",
    "print(f\"   Correct: {correct}/{total}\")\n",
    "print(f\"   Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "print(\"✅ Evaluation complete (model preserved in memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb373e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bb19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5af788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5dc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciurus-env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
